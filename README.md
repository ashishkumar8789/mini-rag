# Mini RAG App ğŸš€

A production-ready Retrieval-Augmented Generation (RAG) application with vector search, reranking, and LLM-powered answers with citations.

**Live Demo:** [Your Vercel URL here]  
**Author:** [Your Name] | [Resume Link]

---

## ğŸ¯ Features

- **Vector Database**: Supabase with pgvector for efficient similarity search
- **Smart Chunking**: 1000-token chunks with 10% overlap for optimal context
- **Embeddings**: OpenAI text-embedding-3-small (1536 dimensions)
- **Reranking**: Cohere Rerank v3.0 for improved relevance
- **LLM Answering**: GPT-3.5-turbo with inline citations
- **Performance Tracking**: Real-time timing and cost estimates
- **Clean UI**: Modern Next.js interface with Tailwind CSS

---

## ğŸ—ï¸ Architecture

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚  Next.js + React + Tailwind
â”‚  (Upload &  â”‚
â”‚    Query)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           API Routes (Next.js)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  /api/upload  â”‚  /api/query  â”‚  /api/stats  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
     â”‚                 â”‚                â”‚
     â–¼                 â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chunking   â”‚  â”‚ Retriever  â”‚  â”‚   LLM    â”‚
â”‚ & Embedding â”‚  â”‚    +       â”‚  â”‚ Answer   â”‚
â”‚  (OpenAI)   â”‚  â”‚  Reranker  â”‚  â”‚Generator â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
      â”‚                â”‚               â”‚
      â–¼                â–¼               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚      Supabase Vector Store (pgvector)      â”‚
â”‚  â€¢ HNSW index for fast similarity search   â”‚
â”‚  â€¢ Metadata filtering & full-text search   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

### Data Flow

1. **Upload Flow**:
   - User pastes text â†’ Split into chunks (1000 tokens, 10% overlap)
   - Generate embeddings (OpenAI) â†’ Store in Supabase with metadata
   
2. **Query Flow**:
   - User asks question â†’ Generate query embedding
   - Retrieve top 10 similar chunks â†’ Rerank to top 5 (Cohere)
   - Generate answer with LLM â†’ Display with citations

---

## ğŸ“Š Configuration Details

### Vector Database
- **Platform**: Supabase (PostgreSQL + pgvector)
- **Collection**: `rag_documents`
- **Dimensions**: 1536 (OpenAI text-embedding-3-small)
- **Index**: HNSW with cosine similarity
- **Upsert Strategy**: Direct insert with batch processing

### Chunking Strategy
- **Size**: 1000 tokens (~750 words)
- **Overlap**: 100 tokens (10%)
- **Method**: Word-based splitting with token estimation
- **Metadata**: Source, title, section, position, chunk params

### Retrieval & Reranking
- **Initial Retrieval**: Top 10 chunks via vector similarity
- **Reranker**: Cohere rerank-english-v3.0
- **Final Results**: Top 5 reranked chunks
- **Scoring**: Combines vector similarity + rerank relevance

### LLM Configuration
- **Model**: GPT-3.5-turbo
- **Temperature**: 0.3 (focused, deterministic)
- **Max Tokens**: 500 (concise answers)
- **System Prompt**: Enforces citation format [1], [2], etc.

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ and npm
- Supabase account (free tier works)
- OpenAI API key
- Cohere API key

### Installation

1. **Clone the repository**
   \`\`\`bash
   git clone <your-repo-url>
   cd mini-rag-app
   \`\`\`

2. **Install dependencies**
   \`\`\`bash
   npm install
   \`\`\`

3. **Set up Supabase**
   - Create a new project at [supabase.com](https://supabase.com)
   - Enable pgvector extension
   - Run the SQL schema from \`supabase_schema.sql\`

4. **Configure environment variables**
   \`\`\`bash
   cp .env.example .env
   \`\`\`
   
   Fill in your credentials:
   \`\`\`env
   OPENAI_API_KEY=sk-...
   COHERE_API_KEY=...
   SUPABASE_URL=https://your-project.supabase.co
   SUPABASE_SERVICE_ROLE_KEY=eyJ...
   \`\`\`

5. **Run development server**
   \`\`\`bash
   npm run dev
   \`\`\`
   
   Open [http://localhost:3000](http://localhost:3000)

---

## ğŸ“¦ Deployment

### Deploy to Vercel

1. **Push to GitHub**
   \`\`\`bash
   git init
   git add .
   git commit -m "Initial commit"
   git remote add origin <your-repo-url>
   git push -u origin main
   \`\`\`

2. **Deploy on Vercel**
   - Go to [vercel.com](https://vercel.com)
   - Import your GitHub repository
   - Add environment variables from \`.env.example\`
   - Deploy!

3. **Verify deployment**
   - Test upload functionality
   - Run sample queries
   - Check browser console for errors

### Alternative Platforms
- **Railway**: \`railway up\`
- **Render**: Connect GitHub repo
- **Fly.io**: \`fly deploy\`

---

## ğŸ“ API Reference

### POST /api/upload
Upload and process text documents.

**Request:**
\`\`\`json
{
  "text": "Your document text...",
  "source": "document.txt",
  "title": "Optional Title"
}
\`\`\`

**Response:**
\`\`\`json
{
  "success": true,
  "stats": {
    "chunksCreated": 5,
    "totalTokens": 4823,
    "estimatedCost": 0.000096,
    "processingTime": 1234
  }
}
\`\`\`

### POST /api/query
Ask questions and get cited answers.

**Request:**
\`\`\`json
{
  "query": "What is the main topic?"
}
\`\`\`

**Response:**
\`\`\`json
{
  "answer": "The main topic is... [1][2]",
  "citations": [
    {
      "index": 1,
      "content": "Relevant chunk text...",
      "source": "document.txt",
      "position": 0,
      "rerankScore": 0.95
    }
  ],
  "timing": {
    "retrievalMs": 123,
    "rerankMs": 456,
    "llmMs": 789,
    "totalMs": 1368
  },
  "usage": {
    "promptTokens": 234,
    "completionTokens": 56,
    "totalTokens": 290,
    "estimatedCost": 0.000345
  }
}
\`\`\`

### GET /api/stats
Get database statistics.

**Response:**
\`\`\`json
{
  "count": 42
}
\`\`\`

---

## ğŸ› ï¸ Tech Stack

- **Framework**: Next.js 14 (React 18)
- **Language**: TypeScript
- **Styling**: Tailwind CSS
- **Vector DB**: Supabase (PostgreSQL + pgvector)
- **Embeddings**: OpenAI (text-embedding-3-small)
- **Reranker**: Cohere (rerank-english-v3.0)
- **LLM**: OpenAI (GPT-3.5-turbo)
- **Deployment**: Vercel

---

## ğŸ’° Cost Estimates

### Per Query (typical)
- Embeddings: ~$0.0001 (1000 tokens)
- Reranking: ~$0.001 (10 documents)
- LLM: ~$0.0003 (500 tokens)
- **Total: ~$0.0014 per query**

### Per Upload (1000 words)
- Chunking: Free
- Embeddings: ~$0.0001
- Storage: Negligible (Supabase free tier)

---

## ğŸ”§ Remarks

### Design Decisions
1. **Supabase over Pinecone**: Lower latency for small datasets, better free tier
2. **Cohere Rerank**: Superior quality vs. raw vector similarity alone
3. **GPT-3.5 vs GPT-4**: 10x cheaper, sufficient for Q&A with good context
4. **Chunk overlap**: Ensures no context loss at boundaries

### Tradeoffs
- **Token-based chunking**: Approximation vs. exact tokenization (accuracy vs. speed)
- **Top-K settings**: 10â†’5 rerank balances cost and quality
- **No streaming**: Simpler implementation, acceptable latency (<2s typical)

### What's Next (v2)
- [ ] PDF/DOCX file upload support
- [ ] Streaming LLM responses
- [ ] Multiple document collections
- [ ] Advanced filters (date, source type)
- [ ] User authentication
- [ ] Query history and analytics

### Known Limitations
- No streaming: Full response wait (1-3s)
- Text-only: No PDF parsing yet
- Single collection: No multi-tenancy
- No auth: Public access (add in production)

---

## ğŸ“œ License

MIT License - feel free to use for learning or production!

---

## ğŸ¤ Submission Checklist

- âœ… Working URL (first screen loads without errors)
- âœ… Public GitHub repo
- âœ… README with setup, architecture, and resume link
- âœ… Clear vector index configuration (Supabase schema)
- âœ… Remarks section (limits, trade-offs, next steps)
- âœ… Retrieved chunks + reranked + LLM answer with citations visible
- âœ… No console errors on production build
- âœ… 5-20 sample text files for testing (see \`sample-docs/\`)

---

**Built with â¤ï¸ for the AI Engineer Assessment**
#   m i n i - r a g  
 